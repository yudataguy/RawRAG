{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw RAG 04: Summarization Techniques\n",
    "\n",
    "Summarizing text with LLMs offers a range of approaches, each suited to different use cases and text lengths. While the process can be straightforward, the choice of method depends on factors such as text length, desired summary detail, and available computational resources.\n",
    "\n",
    "Key summarization approaches include:\n",
    "\n",
    "* Direct summarization: For shorter texts within the LLM's token limit, a single-pass summarization can be effective.\n",
    "\n",
    "* Chunking and hierarchical summarization: For longer texts, breaking the content into smaller chunks, summarizing each, and then summarizing the summaries can overcome token limitations.\n",
    "\n",
    "* Extractive summarization: Identifying and extracting key sentences or passages from the original text.\n",
    "\n",
    "* Rolling summarization: Progressively summarizing the text by maintaining a running summary and updating it as new information is processed.\n",
    "\n",
    "* Query-focused summarization: Tailoring the summary to answer specific questions or focus on particular aspects of the text.\n",
    "\n",
    "* Multi-document summarization: Synthesizing information from multiple sources into a cohesive summary.\n",
    "\n",
    "As LLM context windows expand, the ability to summarize longer texts without chunking is improving. However, human oversight and intervention remain valuable for ensuring accuracy and relevance in summaries, especially for complex or nuanced content.\n",
    "\n",
    "The choice of summarization method should be based on your specific requirements, such as summary length, level of detail, computational resources, and the nature of the source material. Experimenting with different approaches can help determine the most effective method for your particular use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Summarizing Long Text in One Pass\n",
    "\n",
    "This method leverages the impressive capabilities of advanced language models like Google Gemini 1.5 Pro, which boasts an extensive context window of up to 2 million tokens. This approach demonstrates the power of modern LLMs in handling lengthy texts without the need for chunking.\n",
    "\n",
    "Key Points:\n",
    "- Simplicity: Feed the entire text into the model and receive a comprehensive summary in a single operation.\n",
    "- Context Preservation: By processing the full text at once, the model can maintain a holistic understanding, potentially leading to more coherent and contextually accurate summaries.\n",
    "- Resource Considerations: While effective, this method may not be the most cost-efficient or fastest for extremely long texts.\n",
    "\n",
    "The Chunking Debate:\n",
    "There's ongoing discussion in the NLP community about the merits of chunking versus full-text processing. The optimal approach often depends on specific use cases:\n",
    "\n",
    "- Full-text processing excels when:\n",
    "  1. Maintaining overall context is crucial\n",
    "  2. The text length falls within the model's token limit\n",
    "  3. Processing time and cost are not primary concerns\n",
    "\n",
    "- Chunking may be preferred when:\n",
    "  1. Dealing with extremely long documents that exceed token limits\n",
    "  2. Faster processing or lower costs are priorities\n",
    "  3. The focus is on specific sections or themes within a larger text\n",
    "\n",
    "Best Practices:\n",
    "- Evaluate your specific needs: Consider factors like required summary detail, processing speed, and budget constraints.\n",
    "- Experiment with both approaches: Compare the results to determine which method yields the most satisfactory summaries for your use case.\n",
    "- Use judiciously: While powerful, feeding entire textbooks or very long documents may not always be necessary or efficient.\n",
    "\n",
    "Note: To utilize this method, ensure you have access to the long-context \"gemini-1.5-pro\" model, capable of handling up to 2 million tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in ./.venv/lib/python3.12/site-packages (0.7.2)\n",
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.12/site-packages (1.0.1)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.6 in ./.venv/lib/python3.12/site-packages (from google-generativeai) (0.6.6)\n",
      "Requirement already satisfied: google-api-core in ./.venv/lib/python3.12/site-packages (from google-generativeai) (2.19.1)\n",
      "Requirement already satisfied: google-api-python-client in ./.venv/lib/python3.12/site-packages (from google-generativeai) (2.137.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in ./.venv/lib/python3.12/site-packages (from google-generativeai) (2.32.0)\n",
      "Requirement already satisfied: protobuf in ./.venv/lib/python3.12/site-packages (from google-generativeai) (4.25.3)\n",
      "Requirement already satisfied: pydantic in ./.venv/lib/python3.12/site-packages (from google-generativeai) (2.8.2)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.12/site-packages (from google-generativeai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.12/site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in ./.venv/lib/python3.12/site-packages (from google-ai-generativelanguage==0.6.6->google-generativeai) (1.24.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in ./.venv/lib/python3.12/site-packages (from google-api-core->google-generativeai) (1.63.2)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in ./.venv/lib/python3.12/site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.venv/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai) (5.4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in ./.venv/lib/python3.12/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in ./.venv/lib/python3.12/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in ./.venv/lib/python3.12/site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.12/site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./.venv/lib/python3.12/site-packages (from pydantic->google-generativeai) (2.20.1)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in ./.venv/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai) (1.64.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in ./.venv/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai) (1.62.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in ./.venv/lib/python3.12/site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in ./.venv/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.7.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install Google Generative AI package\n",
    "%pip install google-generativeai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the environment variables from the .env file\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "dotenv_path = \".env\"\n",
    "load_dotenv(dotenv_path=dotenv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samyu/Downloads/code/raw-rag/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-1.5-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Dead\n",
      "James Joyce\n",
      "\n",
      "LILY, the caretaker's daughter, was literally run off her feet. Hardly had she brought one gentleman into the little pantry behind the office on the ground floor and helped him off with his overcoat than the wheezy hall-door bell clanged again and she had to scamper along the bare hallway to let in another guest. It was well for her she had not to attend to the ladies also. But Miss Kate and Miss Julia had thought of that and had converted the bathroom upstairs into a ladies' dressing-room. Miss Kate and Miss Julia were there, gossiping and laughing and fussing, walking after each other to the head of the stairs, peering down over the banisters and calling dow\n"
     ]
    }
   ],
   "source": [
    "# load the book The Dead by James Joyce\n",
    "\n",
    "file_path = \"docs/the_dead.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "    \n",
    "print(text[:690])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full prompt for summarizing the short novel generated by Claude 3.5 Sonnet\n",
    "\n",
    "full_prompt = f\"\"\"You are tasked with summarizing a short novel into a concise, easy-to-read format of one to two pages. Follow these instructions carefully to create an effective summary.\n",
    "\n",
    "First, here is the full text of the novel:\n",
    "\n",
    "<novel>\n",
    "{text}\n",
    "</novel>\n",
    "\n",
    "Now, follow these steps to create your summary:\n",
    "\n",
    "1. Read the novel carefully, paying attention to key elements such as plot, characters, themes, and significant events.\n",
    "\n",
    "2. Identify the main plot points and character arcs. Focus on the most important events and character developments that drive the story forward.\n",
    "\n",
    "3. Note the central themes and messages of the novel. What are the core ideas or lessons the author is trying to convey?\n",
    "\n",
    "4. Create a brief outline of the story's structure, including the introduction, rising action, climax, falling action, and resolution.\n",
    "\n",
    "5. Write your summary, keeping the following guidelines in mind:\n",
    "   a. Begin with a brief introduction that includes the title, author, and a one-sentence overview of the plot.\n",
    "   b. Present the main events in chronological order, focusing on cause and effect relationships.\n",
    "   c. Introduce main characters as they appear in the story, providing only essential details about them.\n",
    "   d. Include key dialogues or quotes that are crucial to understanding the story or characters, but use them sparingly.\n",
    "   e. Explain major conflicts and how they are resolved.\n",
    "   f. Discuss the main themes and how they are developed throughout the story.\n",
    "   g. Conclude with the resolution of the story and any final thoughts or messages the author conveys.\n",
    "\n",
    "6. Keep your summary concise and easy to read:\n",
    "   a. Aim for a length of one to two pages (approximately 500-1000 words).\n",
    "   b. Use clear, simple language that can be understood by a general audience.\n",
    "   c. Break your summary into paragraphs for better readability, with each paragraph focusing on a specific part of the story or theme.\n",
    "   d. Use transition words and phrases to ensure smooth flow between ideas and events.\n",
    "\n",
    "7. After writing your summary, review it to ensure you have captured the essence of the novel without including unnecessary details.\n",
    "\n",
    "8. Proofread your summary for any grammatical errors, typos, or unclear sentences.\n",
    "\n",
    "Present your final summary within <summary> tags. Remember to keep it between one to two pages in length, focusing on the most crucial elements of the story while maintaining an easy-to-read format.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<summary>\n",
      "## The Dead: A Summary \n",
      "\n",
      "In James Joyce's \"The Dead,\" we are transported to a vibrant Dublin during the Christmas season to witness the annual dance and dinner hosted by the aging Morkan sisters, Kate and Julia, and their niece, Mary Jane. The story centers around Gabriel Conroy, the sisters' nephew, a self-conscious intellectual, and his wife, Gretta.  \n",
      "\n",
      "The festive evening unfolds with a flurry of music, dancing, and lively conversation.  Gabriel, tasked with delivering the night's speech, grapples with feelings of inadequacy and insecurity, heightened by a tense encounter with Miss Ivors, a fervent Irish nationalist who mocks his intellectualism and West Briton leanings. This encounter casts a shadow over Gabriel’s anticipation of a romantic end to the evening with his wife. \n",
      "\n",
      "As the night progresses, we are introduced to a cast of characters, each embodying different facets of Irish society. Through their interactions, Joyce paints a poignant portrait of a nation grappling with its past, tradition, and identity at the turn of the century. \n",
      "\n",
      "The climax of the story arrives with a simple question. After the party, Gabriel is struck by Gretta's distant demeanor.  When he inquires about it, she reveals that a song sung earlier in the evening, “The Lass of Aughrim,” has triggered a long-forgotten memory of a young man named Michael Furey, who died for love of her in her youth.\n",
      "\n",
      "Gretta’s confession shatters Gabriel’s self-absorbed romantic illusions. He realizes the depth of his wife's past love and the profound effect it continues to have on her. This realization forces Gabriel to confront the superficiality of his own emotions and the limitations of his understanding of both Gretta and himself. He sees his carefully constructed identity crumble, leaving him feeling insignificant and foolish. \n",
      "\n",
      "The story concludes with Gabriel lying awake beside his sleeping wife. As snow falls outside, blanketing the city of Dublin and the grave of Michael Furey, Gabriel experiences a profound epiphany. He grapples with the realization of his own mortality and the ephemeral nature of life. He recognizes the universal and unifying power of death, which ultimately unites him with his wife, her past love, and all of humanity.\n",
      "\n",
      "\"The Dead\" is a poignant exploration of love, loss, memory, and the human condition. Through Joyce’s masterful use of symbolism and subtle character portrayals, the story becomes a meditation on the passage of time, the elusiveness of true connection, and the enduring power of the past to shape our present and future.\n",
      "</summary>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = model.generate_content(full_prompt)\n",
    "\n",
    "print(response.text) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Summarizing Long Text through Chunking\n",
    "\n",
    "While not universally favored, the chunking method remains a practical approach for summarizing extensive texts, particularly when dealing with context window limitations or resource constraints. This technique involves breaking down the text into smaller, manageable segments and summarizing each chunk individually before combining them into a cohesive whole.\n",
    "\n",
    "Advantages:\n",
    "- Overcomes token limits of models with smaller context windows\n",
    "- Can be more computationally efficient for extremely long texts\n",
    "- Allows for parallel processing of chunks, potentially reducing overall processing time\n",
    "\n",
    "Challenges:\n",
    "- Potential loss of broader context: Summarizing isolated chunks may miss overarching themes or connections present in the full text\n",
    "- Inconsistency: Different chunks might be summarized with varying levels of detail or focus\n",
    "- Redundancy: Important information may be repeated across chunk summaries\n",
    "\n",
    "Best Practices for Chunking:\n",
    "1. Intelligent segmentation: Break the text at logical points (e.g., chapter breaks, topic shifts) rather than arbitrary word counts\n",
    "2. Overlap strategy: Include some overlap between chunks to maintain context\n",
    "3. Hierarchical summarization: Summarize chunks, then create a meta-summary of the chunk summaries\n",
    "4. Post-processing: Refine the final summary to eliminate redundancies and ensure coherence\n",
    "\n",
    "While chunking has its limitations, it remains a valuable tool in the summarization toolkit, especially when dealing with very long documents or when using models with more restricted context windows. The key is to apply this method judiciously, being aware of its strengths and weaknesses, and to refine the results as needed to produce a high-quality final summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the text into chunks of 2000 characters\n",
    "\n",
    "from utils import TextProcessor\n",
    "\n",
    "text_processor = TextProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_chunk(chunk, max_output_length=150):\n",
    "    \"\"\"Summarize a single chunk of text using the OpenAI API.\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant that summarizes text.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Summarize the following text in a concise paragraph:\\n\\n{chunk}\",\n",
    "            },\n",
    "        ],\n",
    "        max_tokens=max_output_length,\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize the entire novel by breaking it into chunks and summarizing each chunk\n",
    "\n",
    "def summarize_novel(long_text, max_output_length=150):\n",
    "    # Split the novel into chunks\n",
    "    chunks = text_processor.text_splitter(long_text, char_limit=3000)\n",
    "\n",
    "    # Summarize each chunk\n",
    "    chunk_summaries = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"Summarizing chunk {i+1}/{len(chunks)}...\")\n",
    "        summary = summarize_chunk(chunk, max_output_length)\n",
    "        chunk_summaries.append(summary)\n",
    "\n",
    "    # Combine chunk summaries\n",
    "    combined_summary = \"\\n\\n\".join(chunk_summaries)\n",
    "\n",
    "    # Create a final summary of the entire novel\n",
    "    final_summary = summarize_chunk(combined_summary, max_output_length)\n",
    "\n",
    "    return final_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing chunk 1/30...\n",
      "Summarizing chunk 2/30...\n",
      "Summarizing chunk 3/30...\n",
      "Summarizing chunk 4/30...\n",
      "Summarizing chunk 5/30...\n",
      "Summarizing chunk 6/30...\n",
      "Summarizing chunk 7/30...\n",
      "Summarizing chunk 8/30...\n",
      "Summarizing chunk 9/30...\n",
      "Summarizing chunk 10/30...\n",
      "Summarizing chunk 11/30...\n",
      "Summarizing chunk 12/30...\n",
      "Summarizing chunk 13/30...\n",
      "Summarizing chunk 14/30...\n",
      "Summarizing chunk 15/30...\n",
      "Summarizing chunk 16/30...\n",
      "Summarizing chunk 17/30...\n",
      "Summarizing chunk 18/30...\n",
      "Summarizing chunk 19/30...\n",
      "Summarizing chunk 20/30...\n",
      "Summarizing chunk 21/30...\n",
      "Summarizing chunk 22/30...\n",
      "Summarizing chunk 23/30...\n",
      "Summarizing chunk 24/30...\n",
      "Summarizing chunk 25/30...\n",
      "Summarizing chunk 26/30...\n",
      "Summarizing chunk 27/30...\n",
      "Summarizing chunk 28/30...\n",
      "Summarizing chunk 29/30...\n",
      "Summarizing chunk 30/30...\n",
      "\n",
      "Final Summary:\n",
      "\"In James Joyce's 'The Dead,' the narrative unfolds around an annual dance hosted by the Misses Morkan—sisters Kate and Julia, and their niece Mary Jane. As guests arrive, there is a lively mix of interactions, conversations, and subtle social dynamics playing out among the attendees, including a mix of family members, friends, and various acquaintances. Gabriel Conroy, one of the central characters, navigates through his social anxieties and personal reflections throughout the evening, including a challenging conversation with Lily, the caretaker's daughter. Tensions arise around Freddy Malins' potential intoxication, and Gabriel's reflections on cultural and generational shifts in Ireland. The evening concludes with Gabriel contemplating his deep, unexpressed emotions and\n"
     ]
    }
   ],
   "source": [
    "summary = summarize_novel(text)\n",
    "\n",
    "print(\"\\nFinal Summary:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summaries of individual chunks often lack the depth and coherence of a summary generated from the entire text. This highlights a key limitation of the chunking method: the potential loss of overall context and connections between different parts of the document. To improve chunk-based summaries, we can increase the requested output length for each chunk, allowing for more detailed and nuanced summaries. This approach helps preserve important information that might otherwise be lost in overly concise summaries. However, it's important to balance this with the need for a concise final summary. Experimenting with different output lengths can help find the right balance between detail and brevity, ultimately leading to a more comprehensive and accurate representation of the original text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing chunk 1/30...\n",
      "Summarizing chunk 2/30...\n",
      "Summarizing chunk 3/30...\n",
      "Summarizing chunk 4/30...\n",
      "Summarizing chunk 5/30...\n",
      "Summarizing chunk 6/30...\n",
      "Summarizing chunk 7/30...\n",
      "Summarizing chunk 8/30...\n",
      "Summarizing chunk 9/30...\n",
      "Summarizing chunk 10/30...\n",
      "Summarizing chunk 11/30...\n",
      "Summarizing chunk 12/30...\n",
      "Summarizing chunk 13/30...\n",
      "Summarizing chunk 14/30...\n",
      "Summarizing chunk 15/30...\n",
      "Summarizing chunk 16/30...\n",
      "Summarizing chunk 17/30...\n",
      "Summarizing chunk 18/30...\n",
      "Summarizing chunk 19/30...\n",
      "Summarizing chunk 20/30...\n",
      "Summarizing chunk 21/30...\n",
      "Summarizing chunk 22/30...\n",
      "Summarizing chunk 23/30...\n",
      "Summarizing chunk 24/30...\n",
      "Summarizing chunk 25/30...\n",
      "Summarizing chunk 26/30...\n",
      "Summarizing chunk 27/30...\n",
      "Summarizing chunk 28/30...\n",
      "Summarizing chunk 29/30...\n",
      "Summarizing chunk 30/30...\n",
      "Final Summary with 300 tokens output:\n",
      "In James Joyce's story \"The Dead,\" readers are immersed in the intricate social dynamics of an annual dance hosted by the Morkan sisters and their niece on Usher's Island. The narrative vividly portrays the arrival of guests, including the apprehensively anticipated Freddy Malins, and the blend of jubilation and subtle tension that underpins the evening. Gabriel, a central character, arrives late and navigates through various personal interactions including a somewhat tense conversation with Lily, the caretaker's daughter, about men and marriage. Amidst the festivities filled with music, dancing, and discussions about cultural and generational differences, Gabriel grapples with his insecurities, particularly during his preparation for a speech. Further complexities arise when Gabriel's wife Gretta is stirred by a song that revives memories of her past love, Michael Furey, leading Gabriel into a spiraling reflection on his place in her life and his broader existential concerns. The story encapsulates themes of social cohesion, personal identity, and the inexorable passage of time, culminating in a poignant meditation on life and death, symbolized by the quietly falling snow covering everything uniformly, highlighting the transient and fragile nature of existence.\n"
     ]
    }
   ],
   "source": [
    "# Let's try to summarize the novel with a longer output length of 300 tokens\n",
    "\n",
    "summary = summarize_novel(text, max_output_length=300)\n",
    "\n",
    "print(\"Final Summary with 300 tokens output:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show a noticeable improvement compared to the previous attempt. As demonstrated, generating richer, more detailed summaries for each chunk yields a better overall representation of the text than shorter, more concise summaries.\n",
    "\n",
    "To further enhance our summarization approach, let's explore the rolling summarization method:\n",
    "\n",
    "Begin by summarizing the first chunk of text.\n",
    "For each subsequent chunk: \n",
    "\n",
    "a. Combine it with the existing summary. \n",
    "\n",
    "b. Summarize this combined text.\n",
    "\n",
    "Continue this iterative process through the entire document.\n",
    "The final output is a comprehensive summary of the complete text, developed incrementally.\n",
    "This rolling approach offers several advantages:\n",
    "\n",
    "Maintains context throughout the summarization process\n",
    "Allows for the integration of new information with previously summarized content\n",
    "Potentially captures overarching themes and narratives more effectively\n",
    "Reduces redundancy often found in chunk-based methods\n",
    "By employing this technique, we aim to create a more cohesive and contextually rich summary that better reflects the flow and interconnectedness of the original text. This method is particularly useful for long-form content like novels, where plot development and character arcs span the entire work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling summary implementation\n",
    "\n",
    "def rolling_summarize_novel(novel_text, chunk_size=3000, summary_size=300):\n",
    "    chunks = text_processor.text_splitter(novel_text, chunk_size)\n",
    "    print(\"Processing chunk 1/{}...\".format(len(chunks)))\n",
    "    current_summary = summarize_chunk(chunks[0], summary_size)\n",
    "\n",
    "    for i, chunk in enumerate(chunks[1:], 1):\n",
    "        print(f\"Processing chunk {i+1}/{len(chunks)}...\")\n",
    "\n",
    "        # Combine the current summary with the new chunk\n",
    "        combined_text = f\"{current_summary}\\n\\nNew content:\\n{chunk}\"\n",
    "\n",
    "        # Summarize the combination\n",
    "        current_summary = summarize_chunk(combined_text, summary_size)\n",
    "\n",
    "    return current_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 1/30...\n",
      "Processing chunk 2/30...\n",
      "Processing chunk 3/30...\n",
      "Processing chunk 4/30...\n",
      "Processing chunk 5/30...\n",
      "Processing chunk 6/30...\n",
      "Processing chunk 7/30...\n",
      "Processing chunk 8/30...\n",
      "Processing chunk 9/30...\n",
      "Processing chunk 10/30...\n",
      "Processing chunk 11/30...\n",
      "Processing chunk 12/30...\n",
      "Processing chunk 13/30...\n",
      "Processing chunk 14/30...\n",
      "Processing chunk 15/30...\n",
      "Processing chunk 16/30...\n",
      "Processing chunk 17/30...\n",
      "Processing chunk 18/30...\n",
      "Processing chunk 19/30...\n",
      "Processing chunk 20/30...\n",
      "Processing chunk 21/30...\n",
      "Processing chunk 22/30...\n",
      "Processing chunk 23/30...\n",
      "Processing chunk 24/30...\n",
      "Processing chunk 25/30...\n",
      "Processing chunk 26/30...\n",
      "Processing chunk 27/30...\n",
      "Processing chunk 28/30...\n",
      "Processing chunk 29/30...\n",
      "Processing chunk 30/30...\n",
      "Final Summary:\n",
      "During a hotel stay, Gabriel Conroy delves into his feelings about his wife, Gretta, following the revelation of her past love for Michael Furey, a young man who died tragically. This disclosure leads Gabriel to feel overshadowed and insignificant, prompting deep self-reflection on life's transience and his minor role in Gretta's emotional life. His contemplations are further deepened by thoughts of his Aunt Julia's nearing death, symbolizing a meditation on mortality and the temporary nature of existence. These reflections coincide with the falling snow, which Gabriel perceives as a quiet envelopment of both the living and the dead, including the resting place of Michael Furey. The snow's widespread fall symbolizes the universal, inevitable march towards death and the solitude of human journeys.\n"
     ]
    }
   ],
   "source": [
    "final_summary = rolling_summarize_novel(text)\n",
    "print(\"Final Summary:\")\n",
    "print(final_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion:\n",
    "\n",
    "The exploration of various summarization techniques in this notebook underscores the importance of tailoring your approach to your specific needs and system constraints. There is no one-size-fits-all solution; the best method depends on a careful consideration of your unique circumstances.\n",
    "\n",
    "Key factors to consider when choosing a summarization approach:\n",
    "\n",
    "1. System Limitations:\n",
    "   - Available computational resources\n",
    "   - Token limits of your chosen language model\n",
    "   - Processing time constraints\n",
    "\n",
    "2. Objectives:\n",
    "   - Desired summary length and level of detail\n",
    "   - Importance of preserving context and overarching themes\n",
    "   - Specific focus areas or types of information to prioritize\n",
    "\n",
    "3. Document Characteristics:\n",
    "   - Length and structure of typical documents\n",
    "   - Complexity and interconnectedness of content\n",
    "   - Presence of domain-specific terminology or concepts\n",
    "\n",
    "4. Control and Customization:\n",
    "   - Ability to fine-tune the summarization process\n",
    "   - Flexibility to adjust parameters based on different document types\n",
    "   - Capacity to incorporate domain knowledge or specific rules\n",
    "\n",
    "Recommendations for choosing and implementing a summarization solution:\n",
    "\n",
    "1. Assess Your Needs: Clearly define what you're trying to achieve with your summaries. Are you looking for brief overviews or detailed abstracts? Do you need to capture specific types of information?\n",
    "\n",
    "2. Evaluate Your Constraints: Understand your system's limitations in terms of processing power, memory, and time. This will help you determine whether methods like full-text summarization are feasible or if you need to consider chunking approaches.\n",
    "\n",
    "3. Experiment and Compare: Test different summarization methods on a representative sample of your documents. Compare the results against your objectives and constraints.\n",
    "\n",
    "4. Prioritize Controllability: Opt for solutions that allow you to adjust parameters and fine-tune the process. This ensures you can adapt the summarization to different document types or changing needs.\n",
    "\n",
    "5. Consider Hybrid Approaches: Don't be afraid to combine methods. For example, you might use chunking for initial processing but then apply a rolling summarization for final refinement.\n",
    "\n",
    "6. Implement Feedback Loops: Set up a system to regularly evaluate the quality of your summaries and make adjustments as needed.\n",
    "\n",
    "7. Balance Automation and Human Oversight: While automation is powerful, maintaining some level of human review can help ensure the summaries meet your quality standards and capture critical information.\n",
    "\n",
    "By carefully considering these factors and maintaining control over your summarization process, you can develop a solution that not only meets your current needs but can also be adapted as your requirements evolve. Remember, the goal is to create a system that serves your specific purposes, rather than trying to force-fit a generic solution. With the right approach, you can achieve efficient, accurate, and useful summaries tailored to your unique context."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
