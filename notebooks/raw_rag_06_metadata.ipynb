{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw RAG 06: Extracting Metadata for Enhanced Retrieval\n",
    "\n",
    "In the journey to build more effective Retrieval-Augmented Generation (RAG) systems, we've explored various techniques to improve the quality and relevance of retrieved information. While embedding and chunking form the foundation of many RAG implementations, they alone may not always provide the most accurate context for complex queries.\n",
    "\n",
    "This notebook introduces an additional layer of sophistication to our RAG pipeline: metadata extraction. By leveraging metadata, we can further refine our document retrieval process, leading to more relevant results and improved overall performance.\n",
    "\n",
    "### Key Points\n",
    "\n",
    "1. **Beyond Embedding and Chunking**: We'll explore how metadata can complement traditional retrieval methods.\n",
    "2. **Improved Relevance**: Learn how metadata can help filter and prioritize documents more effectively.\n",
    "3. **Cost Efficiency**: Discover how better retrieval can reduce API costs by minimizing unnecessary queries.\n",
    "4. **Accuracy Enhancement**: Understand how metadata-driven retrieval can improve the accuracy of provided context.\n",
    "\n",
    "### What to Expect\n",
    "\n",
    "In this notebook, we'll dive into one specific approach to metadata extraction and utilization in RAG systems. However, it's crucial to understand that this is just one of many possible strategies to enhance the retrieval process. The field of RAG is rapidly evolving, and new techniques are constantly emerging.\n",
    "\n",
    "We'll build upon the knowledge gained from previous notebooks, particularly the JSON output techniques covered in previous notebook 05 (Pydantic is All You Need). Familiarity with Pydantic and JSON handling will be beneficial as we explore metadata extraction.\n",
    "\n",
    "### Looking Ahead\n",
    "\n",
    "While we'll focus on a particular metadata extraction technique today, keep in mind that this is just the tip of the iceberg. Future explorations may delve into:\n",
    "\n",
    "- Advanced semantic analysis for metadata generation\n",
    "- Multi-modal metadata extraction (text, images, audio)\n",
    "- Dynamic metadata updating and relevance scoring\n",
    "- Integration of external knowledge bases for metadata enrichment\n",
    "\n",
    "By mastering these techniques, you'll be well-equipped to adapt and extend your RAG systems to meet increasingly complex information retrieval challenges.\n",
    "\n",
    "Let's begin our journey into the world of metadata-enhanced RAG!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in ./.venv/lib/python3.12/site-packages (1.35.10)\n",
      "Requirement already satisfied: pydantic in ./.venv/lib/python3.12/site-packages (2.8.2)\n",
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.12/site-packages (1.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.12/site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.12/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.12/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in ./.venv/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.12/site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./.venv/lib/python3.12/site-packages (from pydantic) (2.20.1)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai pydantic python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the environment variables from the .env file\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Specify the path to your .env file if it's not in the same directory\n",
    "dotenv_path = \".env\"\n",
    "load_dotenv(dotenv_path=dotenv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lifted from the previous notebook\n",
    "\n",
    "import json\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from pydantic.json_schema import model_json_schema\n",
    "\n",
    "def pydantic_to_function_schema(model: type[BaseModel]) -> dict:\n",
    "    \"\"\"\n",
    "    Converts a Pydantic model to a function schema.\n",
    "\n",
    "    Args:\n",
    "        model (type[BaseModel]): The Pydantic model to convert.\n",
    "\n",
    "    Returns:\n",
    "        dict: The function schema representing the Pydantic model.\n",
    "    \"\"\"\n",
    "    schema = model_json_schema(model)\n",
    "\n",
    "    function_schema = {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": schema[\"title\"].lower().replace(\" \", \"_\"),\n",
    "            \"description\": schema.get(\"description\", \"\"),\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": schema[\"properties\"],\n",
    "                \"required\": schema.get(\"required\", []),\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "\n",
    "    return function_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, ConfigDict\n",
    "from typing import List, Optional, Dict, Any\n",
    "\n",
    "# Create a sample Pydantic model\n",
    "class QueryMetadata(BaseModel):\n",
    "    model_config = ConfigDict(\n",
    "        title=\"extract query metadata\",\n",
    "        description=\"Based on the user query, extract metadata\"\n",
    "    )\n",
    "    \n",
    "    time_range: List[str] = Field(..., description=\"Identify any time references mentioned in the query. List them in ascending order (from earliest to latest). If no time references are found, leave this field empty.\")\n",
    "    company: str = Field(..., description=\"extract the company name mentioned in the query\")\n",
    "    keywords: List[str] = Field(..., description=\"extract the keywords mentioned in the query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"type\": \"function\",\n",
      "  \"function\": {\n",
      "    \"name\": \"extract_query_metadata\",\n",
      "    \"description\": \"\",\n",
      "    \"parameters\": {\n",
      "      \"type\": \"object\",\n",
      "      \"properties\": {\n",
      "        \"time_range\": {\n",
      "          \"description\": \"Identify any time references mentioned in the query. List them in ascending order (from earliest to latest). If no time references are found, leave this field empty.\",\n",
      "          \"items\": {\n",
      "            \"type\": \"string\"\n",
      "          },\n",
      "          \"title\": \"Time Range\",\n",
      "          \"type\": \"array\"\n",
      "        },\n",
      "        \"company\": {\n",
      "          \"description\": \"extract the company name mentioned in the query\",\n",
      "          \"title\": \"Company\",\n",
      "          \"type\": \"string\"\n",
      "        },\n",
      "        \"keywords\": {\n",
      "          \"description\": \"extract the keywords mentioned in the query\",\n",
      "          \"items\": {\n",
      "            \"type\": \"string\"\n",
      "          },\n",
      "          \"title\": \"Keywords\",\n",
      "          \"type\": \"array\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"time_range\",\n",
      "        \"company\",\n",
      "        \"keywords\"\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "query_metadata_schema = pydantic_to_function_schema(QueryMetadata)\n",
    "print(json.dumps(query_metadata_schema, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import MessageParser\n",
    "\n",
    "message_parser = MessageParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time_range': ['2020', '2022'], 'company': 'Nvidia', 'keywords': ['revenue']}\n"
     ]
    }
   ],
   "source": [
    "query = \"What was Nvidia's revenue between 2020 and 2022?\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You help user with their request.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": query},\n",
    "    ],\n",
    "    model=\"gpt-4-turbo\",\n",
    "    tools=[query_metadata_schema],\n",
    "    tool_choice={\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\"name\": \"extract_query_metadata\"},\n",
    "    },\n",
    ")\n",
    "\n",
    "query_metadata = message_parser.extract_and_parse_arguments(response.choices[0].message)\n",
    "\n",
    "print(query_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, ConfigDict\n",
    "from typing import Optional, Dict, Any, List\n",
    "import json\n",
    "\n",
    "\n",
    "class GuestRequest(BaseModel):\n",
    "    model_config = ConfigDict(\n",
    "        title=\"GuestRequest Model\",\n",
    "        description=\"Based on the user request, return the guest request details.\",\n",
    "    )\n",
    "    room_number: str = Field(..., description=\"guest room number\")\n",
    "    guest_name: Optional[str] = Field(None, description=\"guest name\")\n",
    "    request: str = Field(..., description=\"guest request\")\n",
    "\n",
    "\n",
    "class RoomService(BaseModel):\n",
    "    model_config = ConfigDict(\n",
    "        title=\"RoomService Model\",\n",
    "        description=\"Order room service for a guest.\",\n",
    "    )\n",
    "    room_number: str = Field(..., description=\"guest room number\")\n",
    "    menu_item: str = Field(..., description=\"menu item to order\")\n",
    "    quantity: int = Field(..., description=\"quantity of the item\")\n",
    "\n",
    "\n",
    "# Function to convert Pydantic model to function schema\n",
    "def pydantic_to_json_schema(model: type[BaseModel]) -> Dict[str, Any]:\n",
    "    schema = model.model_json_schema()\n",
    "\n",
    "    function_schema = {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": schema.get(\"title\", model.__name__).lower().replace(\" \", \"_\"),\n",
    "            \"description\": schema.get(\"description\", \"\"),\n",
    "            \"parameters\": {\"type\": \"object\", \"properties\": {}, \"required\": []},\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Correctly extract the overall schema description\n",
    "    model_config = getattr(model, \"model_config\", None)\n",
    "    if model_config and isinstance(model_config, dict):\n",
    "        function_schema[\"function\"][\"description\"] = model_config.get(\"description\", \"\")\n",
    "\n",
    "    for field_name, field in model.model_fields.items():\n",
    "        field_info = field.json_schema_extra or {}\n",
    "        field_type = field.annotation\n",
    "\n",
    "        if field.is_required():\n",
    "            function_schema[\"function\"][\"parameters\"][\"required\"].append(field_name)\n",
    "\n",
    "        # Correctly extract the description from the field\n",
    "        description = field_info.get(\"description\") or field.description or \"\"\n",
    "\n",
    "        function_schema[\"function\"][\"parameters\"][\"properties\"][field_name] = {\n",
    "            \"type\": \"string\" if field_type in (str, Optional[str]) else \"integer\",\n",
    "            \"description\": description,\n",
    "        }\n",
    "\n",
    "    return function_schema\n",
    "\n",
    "\n",
    "def generate_function_descriptions_and_tool_choice(\n",
    "    models: List[type[BaseModel]], chosen_function: str\n",
    ") -> Dict[str, Any]:\n",
    "    function_descriptions = [pydantic_to_json_schema(model) for model in models]\n",
    "\n",
    "    tool_choice = {\"type\": \"function\", \"function\": {\"name\": chosen_function}}\n",
    "\n",
    "    return {\"function_descriptions\": function_descriptions, \"tool_choice\": tool_choice}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function Descriptions:\n",
      "[\n",
      "  {\n",
      "    \"type\": \"function\",\n",
      "    \"function\": {\n",
      "      \"name\": \"guestrequest_model\",\n",
      "      \"description\": \"Based on the user request, return the guest request details.\",\n",
      "      \"parameters\": {\n",
      "        \"type\": \"object\",\n",
      "        \"properties\": {\n",
      "          \"room_number\": {\n",
      "            \"type\": \"string\",\n",
      "            \"description\": \"guest room number\"\n",
      "          },\n",
      "          \"guest_name\": {\n",
      "            \"type\": \"string\",\n",
      "            \"description\": \"guest name\"\n",
      "          },\n",
      "          \"request\": {\n",
      "            \"type\": \"string\",\n",
      "            \"description\": \"guest request\"\n",
      "          }\n",
      "        },\n",
      "        \"required\": [\n",
      "          \"room_number\",\n",
      "          \"request\"\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"function\",\n",
      "    \"function\": {\n",
      "      \"name\": \"roomservice_model\",\n",
      "      \"description\": \"Order room service for a guest.\",\n",
      "      \"parameters\": {\n",
      "        \"type\": \"object\",\n",
      "        \"properties\": {\n",
      "          \"room_number\": {\n",
      "            \"type\": \"string\",\n",
      "            \"description\": \"guest room number\"\n",
      "          },\n",
      "          \"menu_item\": {\n",
      "            \"type\": \"string\",\n",
      "            \"description\": \"menu item to order\"\n",
      "          },\n",
      "          \"quantity\": {\n",
      "            \"type\": \"integer\",\n",
      "            \"description\": \"quantity of the item\"\n",
      "          }\n",
      "        },\n",
      "        \"required\": [\n",
      "          \"room_number\",\n",
      "          \"menu_item\",\n",
      "          \"quantity\"\n",
      "        ]\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "]\n",
      "\n",
      "Tool Choice:\n",
      "{\n",
      "  \"type\": \"function\",\n",
      "  \"function\": {\n",
      "    \"name\": \"get_guest_request\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "models = [GuestRequest, RoomService]\n",
    "chosen_function = \"get_guest_request\"\n",
    "\n",
    "result = generate_function_descriptions_and_tool_choice(models, chosen_function)\n",
    "\n",
    "print(\"Function Descriptions:\")\n",
    "print(json.dumps(result[\"function_descriptions\"], indent=2))\n",
    "print(\"\\nTool Choice:\")\n",
    "print(json.dumps(result[\"tool_choice\"], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion: Elevating RAG and LLM Processes with Metadata\n",
    "\n",
    "As we conclude this exploration of metadata extraction in Retrieval-Augmented Generation (RAG) systems, it's clear that we've taken a significant step forward in enhancing the capabilities of our AI-powered information retrieval and generation processes.\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Building on Foundations**: We've leveraged the JSON parsing techniques from our previous notebook, demonstrating how foundational skills can be applied to more advanced concepts.\n",
    "\n",
    "2. **Metadata as a Powerful Filter**: By extracting and utilizing metadata, we've unlocked a new dimension of document relevance, allowing for more nuanced and accurate retrieval.\n",
    "\n",
    "3. **Efficiency Gains**: The implementation of metadata-driven retrieval has shown potential for reducing API costs and improving overall system efficiency.\n",
    "\n",
    "4. **Improved Context Accuracy**: Our metadata approach has demonstrated how we can provide LLMs with more relevant context, potentially leading to higher quality outputs.\n",
    "\n",
    "5. **Flexibility in Implementation**: The techniques we've explored are adaptable, allowing for customization based on specific use cases and data types.\n",
    "\n",
    "### Practical Applications\n",
    "\n",
    "The skills and concepts covered in this notebook open up a range of possibilities for improving RAG and LLM processes:\n",
    "\n",
    "- **Enhanced Query Understanding**: Use metadata to better interpret user queries and match them with relevant documents.\n",
    "- **Dynamic Content Filtering**: Implement metadata-based filters that can adapt to user preferences or specific task requirements.\n",
    "- **Improved Data Governance**: Leverage metadata for better tracking and management of information sources within your RAG system.\n",
    "- **Multi-Modal RAG**: Extend these concepts to handle metadata from various data types, including images, audio, and video.\n",
    "\n",
    "### Looking Ahead\n",
    "\n",
    "While we've made significant progress, this is just one step in the ongoing evolution of RAG systems. As you continue to develop and refine your implementations, consider:\n",
    "\n",
    "- Integrating more advanced NLP techniques for metadata extraction\n",
    "- Exploring machine learning approaches to dynamically weight metadata importance\n",
    "- Investigating ways to combine metadata with other retrieval enhancement techniques\n",
    "\n",
    "Remember, the goal is not just to retrieve information, but to provide LLMs with the most relevant and context-rich data possible. By mastering metadata extraction and utilization, you're equipping yourself with a powerful tool to achieve this goal.\n",
    "\n",
    "As we move forward, keep experimenting, iterating, and pushing the boundaries of what's possible with RAG and LLMs. The techniques we've explored today are your stepping stones to building more intelligent, efficient, and capable RAG systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
