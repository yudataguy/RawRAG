{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw RAG 01: The Basics\n",
    "\n",
    "I'm sure you are familiar with RAG. In case you are not, here is a brief explanation. \n",
    "\n",
    "**Retrieval-Augmented Generation (RAG)** is an innovative approach in natural language processing that combines the power of large language models with external knowledge retrieval. It addresses some of the limitations of traditional language models by allowing them to access and utilize up-to-date, specific information from a knowledge base.\n",
    "\n",
    "## Key Components of RAG:\n",
    "\n",
    "* *Retriever*: Searches and selects relevant information from a knowledge base.\n",
    "* *Generator*: A language model that produces responses based on the retrieved information and the input query.\n",
    "* *Knowledge Base*: A collection of documents or data that serves as an external source of information.\n",
    "\n",
    "## How RAG Works:\n",
    "\n",
    "When given a query, the retriever searches the knowledge base for relevant information.\n",
    "The retrieved information is then passed to the generator along with the original query.\n",
    "The generator uses this context to produce a more informed and accurate response.\n",
    "\n",
    "## Benefits of RAG:\n",
    "\n",
    "* *Up-to-date Information*: Can access the latest information, unlike static language models.\n",
    "* *Reduced Hallucination*: By grounding responses in retrieved facts, RAG reduces the likelihood of generating false or irrelevant information.\n",
    "* *Transparency*: The retrieved information can be presented alongside the generated response, providing insight into the model's \"reasoning.\"\n",
    "* *Flexibility*: The knowledge base can be easily updated or customized for specific domains or applications.\n",
    "\n",
    "RAG represents a significant step forward in creating more reliable, informative, and context-aware systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will implement a Retrieval-Augmented Generation (RAG) system using a \"raw\" approach. Instead of relying on high-level frameworks like LangChain or LlamaIndex, I'll build our system using only basic Python code, existing OpenAI (and other commercial LLMs) libraries, and a local vector database. This approach offers several benefits:\n",
    "\n",
    "* Greater understanding: By implementing each component ourselves, we gain deeper insights into how RAG systems work \"under the hood\".\n",
    "* Flexibility: We can easily modify and optimize each step for our specific needs.\n",
    "* Minimal dependencies: This implementation will have fewer external dependencies, reducing potential conflicts and security risks.\n",
    "* Educational value: This approach is excellent for learning the fundamentals of RAG systems.\n",
    "\n",
    "**Note**: You will need an OpenAI API key for the embedding and generation processes. Ensure you have this set up before proceeding.\n",
    "We will walk through the following steps to create our RAG system:\n",
    "\n",
    "* Data Ingestion: Load and preprocess the input documents from our knowledge base.\n",
    "* Embedding Generation: Convert the preprocessed text into dense vector representations (embeddings) using OpenAI's embedding model.\n",
    "* Vector Database Storage: Store the generated embeddings efficiently in a local vector database for quick retrieval.\n",
    "* Semantic Retrieval: Given a user query, find the most relevant documents by comparing the query embedding to those in our database.\n",
    "* Augmented Generation: Combine the retrieved relevant context with the original query to generate an informed and accurate response using OpenAI's language model.\n",
    "\n",
    "Each step will be explained in detail, with Python code examples and explanations to help you understand the process thoroughly. By the end of this notebook, you'll have a functional RAG system built from scratch and a solid foundation for more advanced implementations.\n",
    "Let's begin by setting up our environment and importing the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Requirement already satisfied: openai in ./.venv/lib/python3.12/site-packages (1.35.10)',\n",
       " 'Requirement already satisfied: faiss-cpu in ./.venv/lib/python3.12/site-packages (1.8.0.post1)',\n",
       " 'Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (1.26.4)',\n",
       " 'Requirement already satisfied: python-dotenv in ./.venv/lib/python3.12/site-packages (1.0.1)',\n",
       " 'Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.12/site-packages (from openai) (4.4.0)',\n",
       " 'Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.12/site-packages (from openai) (1.9.0)',\n",
       " 'Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.12/site-packages (from openai) (0.27.0)',\n",
       " 'Requirement already satisfied: pydantic<3,>=1.9.0 in ./.venv/lib/python3.12/site-packages (from openai) (2.8.2)',\n",
       " 'Requirement already satisfied: sniffio in ./.venv/lib/python3.12/site-packages (from openai) (1.3.1)',\n",
       " 'Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.12/site-packages (from openai) (4.66.4)',\n",
       " 'Requirement already satisfied: typing-extensions<5,>=4.7 in ./.venv/lib/python3.12/site-packages (from openai) (4.12.2)',\n",
       " 'Requirement already satisfied: packaging in ./.venv/lib/python3.12/site-packages (from faiss-cpu) (24.1)',\n",
       " 'Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.7)',\n",
       " 'Requirement already satisfied: certifi in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)',\n",
       " 'Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)',\n",
       " 'Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)',\n",
       " 'Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)',\n",
       " 'Requirement already satisfied: pydantic-core==2.20.1 in ./.venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)',\n",
       " '',\n",
       " '\\x1b[1m[\\x1b[0m\\x1b[34;49mnotice\\x1b[0m\\x1b[1;39;49m]\\x1b[0m\\x1b[39;49m A new release of pip is available: \\x1b[0m\\x1b[31;49m24.0\\x1b[0m\\x1b[39;49m -> \\x1b[0m\\x1b[32;49m24.1.2\\x1b[0m',\n",
       " '\\x1b[1m[\\x1b[0m\\x1b[34;49mnotice\\x1b[0m\\x1b[1;39;49m]\\x1b[0m\\x1b[39;49m To update, run: \\x1b[0m\\x1b[32;49mpip install --upgrade pip\\x1b[0m']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only necessary libraries are imported, such as openai and faiss. This aims to reduce the library dependencies and make the notebook more lightweight.\n",
    "\n",
    "%pip install openai faiss-cpu numpy python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the environment variables from the .env file\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "dotenv_path = \".env\"\n",
    "load_dotenv(dotenv_path=dotenv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "“The Lottery [abridged]” (1948)--- By Shirley Jackson\n",
      "\n",
      "The people of the village began to gather in the square, between the post office and the bank, around ten o'clock; in some towns there were so many people that the lottery took two days and had to be started on June 2nd.  But in this village, where there were only about three hundred people, the whole lottery took less than two hours, so it could begin at ten o'clock in the morning and still be through in time to allow the villagers to get home for noon dinner. \n",
      "The children assembled first, of course. Bobby Martin had already stuffed his pockets full of stones, and the other boys soon followed his example, selecting the smooth\n"
     ]
    }
   ],
   "source": [
    "# Please see the utils.py file for the implementation of the text_splitter function.\n",
    "# Additional information on utils.py can be read at utils_readme.md\n",
    "\n",
    "from utils import TextProcessor\n",
    "\n",
    "text_process = TextProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of paragraphs: 23\n",
      "\n",
      "First 5 paragraphs:\n",
      "“The Lottery [abridged]” (1948)--- By Shirley Jackson The people of the village began to gather in the square, between the post office and the bank, around ten o'clock; in some towns there were so many people that the lottery took two days and had to be started on June 2nd.\n",
      "\n",
      "---\n",
      "\n",
      "But in this village, where there were only about three hundred people, the whole lottery took less than two hours, so it could begin at ten o'clock in the morning and still be through in time to allow the villagers to get home for noon dinner. The children assembled first, of course.\n",
      "\n",
      "---\n",
      "\n",
      "Bobby Martin had already stuffed his pockets full of stones, and the other boys soon followed his example, selecting the smoothest and roundest stones; Bobby and Harry Jones and Dickie Delacroix-- the villagers pronounced this name \"Dellacroy\"--eventually made a great pile of stones in one corner of the square and guarded it against the raids of the other boys. The lottery was conducted--as were the square dances, the teen club, the Halloween program--by Mr.\n",
      "\n",
      "---\n",
      "\n",
      "Summers, who had time and energy to devote to civic activities. When he arrived in the square, carrying the black wooden box, there was a murmur of conversation among the villagers, and he waved and called, \"Little late today, folks. \" There was a great deal of fussing to be done before Mr. Summers declared the lottery open. There were the lists to make up--of heads of families- heads of households in each family. There was the proper swearing-in of Mr.\n",
      "\n",
      "---\n",
      "\n",
      "Summers by the postmaster, as the official of the lottery. Mrs. Hutchinson reached her husband, and Mr. Summers, who had been waiting, said cheerfully. \"Thought we were going to have to get on without you, Tessie. \" Mrs. Hutchinson said, grinning, \"Wouldn't have me leave m'dishes in the sink, now, would you. Joe?\" and soft laughter ran through the crowd as the people stirred back into position after Mrs. Hutchinson's arrival. \"Well, now. \" Mr.\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the text from a file. Original text: \"The Lottery\" by Shirley Jackson https://www.newyorker.com/magazine/1948/06/26/the-lottery \n",
    "\n",
    "file_path = 'docs/the_lottery_text.txt'\n",
    "\n",
    "with open(file_path, 'r', encoding=\"utf-8\") as file:\n",
    "  text = file.read()\n",
    "\n",
    "print(text[:690])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of paragraphs: 23\n",
      "\n",
      "First 5 paragraphs:\n",
      "“The Lottery [abridged]” (1948)--- By Shirley Jackson The people of the village began to gather in the square, between the post office and the bank, around ten o'clock; in some towns there were so many people that the lottery took two days and had to be started on June 2nd.\n",
      "\n",
      "---\n",
      "\n",
      "But in this village, where there were only about three hundred people, the whole lottery took less than two hours, so it could begin at ten o'clock in the morning and still be through in time to allow the villagers to get home for noon dinner. The children assembled first, of course.\n",
      "\n",
      "---\n",
      "\n",
      "Bobby Martin had already stuffed his pockets full of stones, and the other boys soon followed his example, selecting the smoothest and roundest stones; Bobby and Harry Jones and Dickie Delacroix-- the villagers pronounced this name \"Dellacroy\"--eventually made a great pile of stones in one corner of the square and guarded it against the raids of the other boys. The lottery was conducted--as were the square dances, the teen club, the Halloween program--by Mr.\n",
      "\n",
      "---\n",
      "\n",
      "Summers, who had time and energy to devote to civic activities. When he arrived in the square, carrying the black wooden box, there was a murmur of conversation among the villagers, and he waved and called, \"Little late today, folks. \" There was a great deal of fussing to be done before Mr. Summers declared the lottery open. There were the lists to make up--of heads of families- heads of households in each family. There was the proper swearing-in of Mr.\n",
      "\n",
      "---\n",
      "\n",
      "Summers by the postmaster, as the official of the lottery. Mrs. Hutchinson reached her husband, and Mr. Summers, who had been waiting, said cheerfully. \"Thought we were going to have to get on without you, Tessie. \" Mrs. Hutchinson said, grinning, \"Wouldn't have me leave m'dishes in the sink, now, would you. Joe?\" and soft laughter ran through the crowd as the people stirred back into position after Mrs. Hutchinson's arrival. \"Well, now. \" Mr.\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pre-process the text into chunks in order to for vectorized embedding process\n",
    "\n",
    "paragraphs = text_process.text_splitter(text, char_limit=500)\n",
    "\n",
    "print(\"Total number of paragraphs:\", len(paragraphs))\n",
    "\n",
    "print(\"\\nFirst 5 paragraphs:\")\n",
    "for paragraph in paragraphs[:5]:\n",
    "  print(paragraph)\n",
    "  print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "import faiss \n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text: str, model: str = \"text-embedding-3-small\"):\n",
    "    \"\"\"\n",
    "    Get embedding for a given text using OpenAI's API.\n",
    "\n",
    "    Parameters:\n",
    "    text (str): The input text for which the embedding needs to be generated.\n",
    "    model (str): The name of the model to use for generating the embedding. Default is \"text-embedding-3-small\", the cheapest latest model.\n",
    "\n",
    "    Returns:\n",
    "    list: The embedding vector for the input text.\n",
    "    \"\"\"\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    return client.embeddings.create(input=[text], model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embedding for all paragraphs\n",
    "embeddings = [get_embedding(text) for text in paragraphs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize FAISS index\n",
    "dimension = len(embeddings[0])  # Dimension of the embedding\n",
    "index = faiss.IndexFlatL2(dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add embeddings to the FAISS index\n",
    "index.add(np.array(embeddings).astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a search\n",
    "query = \"When was it written?\"\n",
    "query_embedding = get_embedding(query)\n",
    "\n",
    "k = 2  # Number of nearest neighbors to retrieve\n",
    "distances, indices = index.search(np.array([query_embedding]).astype(\"float32\"), k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: When was it written?\n",
      "Nearest neighbors:\n",
      "1. “The Lottery [abridged]” (1948)--- By Shirley Jackson The people of the village began to gather in the square, between the post office and the bank, around ten o'clock; in some towns there were so many people that the lottery took two days and had to be started on June 2nd. (Distance: 1.5569045543670654)\n",
      "2. Summers said, and Bill Hutchinson reached into the box and felt around, bringing his hand out at last with the slip of paper in it. The crowd was quiet. A girl whispered, \"I hope it's not Nancy,\" and the sound of the whisper reached the edges of the crowd. \"It's not the way it used to be. \" Old Man Warner said clearly. \"People ain't the way they used to be. \" \"All right,\" Mr. Summers said. \"Open the papers. Harry, you open little Dave's. \" Mr. (Distance: 1.602304458618164)\n"
     ]
    }
   ],
   "source": [
    "# Retrieve and print results\n",
    "print(f\"Query: {query}\")\n",
    "print(\"Nearest neighbors:\")\n",
    "for i, idx in enumerate(indices[0]):\n",
    "    print(f\"{i+1}. {paragraphs[idx]} (Distance: {distances[0][i]})\")\n",
    "    \n",
    "# Combine the paragraphs into a single context\n",
    "context = \" \".join(paragraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The article was written in 1948.\n"
     ]
    }
   ],
   "source": [
    "# Send the retrieved paragraphs along with the query to the OpenAI API to generate a complete answer\n",
    "\n",
    "full_query = f\"\"\"Use the below context to answer the subsequent question. If the answer cannot be found, write \"I don't know.\"\n",
    "\n",
    "Article:\n",
    "\\\"\\\"\\\"\n",
    "{context}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "Question: {query}\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You answer questions for the user.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": full_query},\n",
    "    ],\n",
    "    model=\"gpt-4-turbo\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion: You've Built Your Own RAG System!\n",
    "\n",
    "Congratulations! You've successfully implemented a Retrieval-Augmented Generation (RAG) system from scratch using pure Python and minimal external libraries. Let's recap what you've accomplished:\n",
    "\n",
    "1. **Built a complete RAG pipeline**: From data ingestion to augmented generation, you've created each component of a functional RAG system.\n",
    "\n",
    "2. **Gained deep insights**: By implementing each step yourself, you've developed a thorough understanding of how RAG systems work under the hood.\n",
    "\n",
    "3. **Developed practical skills**: You've worked with embeddings, vector databases, and language models - all valuable skills in RAG.\n",
    "\n",
    "4. **Created a flexible foundation**: Your \"raw\" implementation can be easily modified and extended for various applications.\n",
    "\n",
    "## Key Takeaways:\n",
    "\n",
    "- RAG systems enhance language models with external knowledge, improving accuracy and reducing hallucinations.\n",
    "- Efficient embedding and retrieval are crucial for RAG performance.\n",
    "- Proper context integration is key to generating relevant and accurate responses.\n",
    "\n",
    "## Next Steps:\n",
    "\n",
    "Now that you have a working RAG system, consider these ideas to further your learning:\n",
    "\n",
    "1. **Experiment with different embedding models** to see how they affect retrieval accuracy.\n",
    "2. **Try various vector databases** and compare their performance.\n",
    "3. **Implement additional preprocessing steps** to improve the quality of your knowledge base.\n",
    "4. **Explore advanced retrieval techniques** like hybrid search or re-ranking.\n",
    "5. **Add a simple UI** to interact with your RAG system more easily.\n",
    "\n",
    "Remember, the field of LLM and RAG is constantly evolving. Keep exploring, experimenting, and building to stay at the forefront of this exciting field!\n",
    "\n",
    "---\n",
    "\n",
    "**Note**: While we could have used direct HTTP requests to process OpenAI API calls for an even more \"raw\" approach, our focus was on understanding RAG implementation without additional frameworks. The key takeaway is that you can create a functional RAG system using basic Python libraries and concepts, giving you full control and understanding of the process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
