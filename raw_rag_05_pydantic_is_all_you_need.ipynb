{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw RAG 05: Pydantic is All You Need (Really!)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In the world of Retrieval-Augmented Generation (RAG) systems, structured data plays a crucial role in ensuring accuracy and facilitating seamless integration with other components. While there are numerous libraries and frameworks available for handling JSON responses from Language Models (LLMs), this notebook focuses on a lightweight and flexible approach using only the Pydantic and json libraries.\n",
    "Why Pydantic?\n",
    "\n",
    "* **Type Safety**: Pydantic provides runtime type checking and data validation.\n",
    "* **Simplicity**: It offers a straightforward way to define data models using Python type annotations.\n",
    "* **Flexibility**: Easily extensible to accommodate complex data structures.\n",
    "* **Performance**: Pydantic is optimized for speed, making it suitable for high-performance applications.\n",
    "\n",
    "## Objectives\n",
    "In this notebook, we will:\n",
    "\n",
    "* Introduce basic Pydantic models for structuring LLM responses\n",
    "* Demonstrate how to parse JSON responses into Pydantic models\n",
    "* Explore advanced Pydantic features for handling complex data structures\n",
    "* Discuss best practices for integrating Pydantic into your RAG pipeline\n",
    "\n",
    "By the end of this notebook, you'll have a solid understanding of how to use Pydantic for JSON parsing in your RAG system. This knowledge will empower you to adapt and extend these concepts to fit your specific needs, ensuring robust and type-safe data handling throughout your project.\n",
    "Let's dive in and explore the power of Pydantic in RAG systems!\n",
    "\n",
    "Reference:\n",
    "- [Pydantic](https://pydantic-docs.helpmanual.io/)\n",
    "- [Video: Pydantic is All You Need](https://www.youtube.com/watch?v=yj-wSRJwrrc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in ./.venv/lib/python3.12/site-packages (1.35.10)\n",
      "Requirement already satisfied: pydantic in ./.venv/lib/python3.12/site-packages (2.8.2)\n",
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.12/site-packages (1.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.12/site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.12/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.12/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in ./.venv/lib/python3.12/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.12/site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./.venv/lib/python3.12/site-packages (from pydantic) (2.20.1)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install needed packages\n",
    "\n",
    "%pip install openai pydantic python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the environment variables from the .env file\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "dotenv_path = \".env\"\n",
    "load_dotenv(dotenv_path=dotenv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from openai.types.chat.completion_create_params import ResponseFormat\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option A: Direct JSON Response Request\n",
    "\n",
    "Leveraging the built-in JSON support of the ChatGPT API, we can streamline our process by directly requesting responses in JSON format. This approach eliminates the need for additional parsing steps, potentially reducing processing time and complexity.\n",
    "\n",
    "Key points:\n",
    "\n",
    "* Include the phrase \"json_response_format\" in your query\n",
    "* Set `response_format={\"type\": 'json_object'}` in the API call\n",
    "* Ensures a structured, easily parseable response\n",
    "\n",
    "By utilizing this method, we can efficiently obtain structured data from the LLM, setting the stage for seamless integration with our RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"room_number\": \"101\",\n",
      "  \"guest_name\": \"John Smith\",\n",
      "  \"request\": \"extra towels\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Note: you must include the word \"json_response_format\" in query and response_format={\"type\": 'json_object'} in function to get the response in json format\n",
    "\n",
    "full_query = f\"\"\"You are a customer relations manager at a hotel. A guest named John Smith is staying in room 101 and has requested extra towels. Write a message to the housekeeping staff instructing them to fulfill the request.\n",
    "\n",
    "json_response_format: room_number, guest_name, request\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You help user with their request.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": full_query},\n",
    "    ],\n",
    "    response_format={\"type\": 'json_object'},\n",
    "    model=\"gpt-4-turbo\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "resp = response.choices[0].message.content\n",
    "\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option B: ChatGPT API Function Call for JSON Responses\n",
    "\n",
    "While Option A offers simplicity, it may lack robustness when dealing with inconsistent field types. The ChatGPT API's function call feature provides a more structured and reliable alternative for obtaining JSON responses.\n",
    "\n",
    "Key advantages:\n",
    "\n",
    "* Enhanced control over response structure\n",
    "* Improved consistency in field types\n",
    "* Reduced error potential in complex scenarios\n",
    "\n",
    "By leveraging function calls, we can define precise schemas for our desired outputs, ensuring that the LLM adheres to our specified format. This method is particularly valuable when working with intricate data structures or when maintaining strict type consistency is crucial for downstream processing in your RAG pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function tools and output schema\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_guest_request\",\n",
    "            \"description\": \"Get the guest request\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"room_number\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"guest room number\",\n",
    "                    },\n",
    "                    \"guest_name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"guest name\",\n",
    "                    },\n",
    "                    \"request\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"guest request\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"room_number\", \"request\"],\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_QltSm9v9215FvsZXtaueBM9q', function=Function(arguments='{\"room_number\":\"101\",\"guest_name\":\"John Smith\",\"request\":\"extra towels\"}', name='get_guest_request'), type='function')])\n"
     ]
    }
   ],
   "source": [
    "# Call the function\n",
    "\n",
    "new_query = f\"\"\"You are a customer relations manager at a hotel. A guest named John Smith is staying in room 101 and has requested extra towels. Write a message to the housekeeping staff instructing them to fulfill the request.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You help user with their request.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": new_query},\n",
    "    ],\n",
    "    model=\"gpt-4-turbo\",\n",
    "    tools=tools,\n",
    "    tool_choice={\"type\": \"function\", \"function\": {\"name\": \"get_guest_request\"}}\n",
    ")\n",
    "\n",
    "function_call_resp = response.choices[0].message\n",
    "\n",
    "print(function_call_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's build a function to extract and parse the arguments from the response\n",
    "\n",
    "import json\n",
    "\n",
    "def extract_and_parse_arguments(message) -> dict:\n",
    "    if message.tool_calls and len(message.tool_calls) > 0:\n",
    "        first_tool_call = message.tool_calls[0]\n",
    "        arguments_str = first_tool_call.function.arguments\n",
    "        return json.loads(arguments_str)\n",
    "    else:\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'room_number': '101', 'guest_name': 'John Smith', 'request': 'extra towels'}\n"
     ]
    }
   ],
   "source": [
    "parsed_args = extract_and_parse_arguments(function_call_resp)\n",
    "\n",
    "print(parsed_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option C: Pydantic for JSON Schema Generation\n",
    "\n",
    "While manually crafting JSON schemas is feasible, it can become unwieldy and error-prone, especially for complex structures. Pydantic offers a more elegant and maintainable solution for schema creation.\n",
    "\n",
    "Key benefits:\n",
    "\n",
    "* Improved readability and maintainability\n",
    "* Automatic type validation and error checking\n",
    "* Seamless conversion to JSON schema format\n",
    "\n",
    "By leveraging Pydantic's intuitive class-based model definitions, we can create clear, structured schemas that are easy to understand and modify. This approach not only reduces the likelihood of errors but also enhances code quality and developer productivity in your RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, ConfigDict\n",
    "from typing import Optional, Dict, List, Any\n",
    "\n",
    "# Create a Pydantic model to represent the guest request\n",
    "class GuestRequest(BaseModel):\n",
    "    model_config = ConfigDict(\n",
    "        title=\"extract user request detail\",\n",
    "        description=\"Based on the user request, return the guest request details.\",\n",
    "    )\n",
    "    room_number: str = Field(..., description=\"guest room number\")\n",
    "    guest_name: Optional[str] = Field(None, description=\"guest name\")\n",
    "    request: str = Field(..., description=\"guest request\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"type\": \"function\",\n",
      "  \"function\": {\n",
      "    \"name\": \"extract_user_request_detail\",\n",
      "    \"description\": \"\",\n",
      "    \"parameters\": {\n",
      "      \"type\": \"object\",\n",
      "      \"properties\": {\n",
      "        \"room_number\": {\n",
      "          \"type\": \"string\",\n",
      "          \"description\": \"guest room number\"\n",
      "        },\n",
      "        \"guest_name\": {\n",
      "          \"type\": \"string\",\n",
      "          \"description\": \"guest name\"\n",
      "        },\n",
      "        \"request\": {\n",
      "          \"type\": \"string\",\n",
      "          \"description\": \"guest request\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"room_number\",\n",
      "        \"request\"\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from utils import MessageParser, SchemaConverter\n",
    "\n",
    "message_parser = MessageParser()\n",
    "schema_converter = SchemaConverter()\n",
    "\n",
    "pydantic_tool = schema_converter.pydantic_to_function_schema(GuestRequest)\n",
    "print(json.dumps(pydantic_tool, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_AmSkDHwAPh37iLHVOmUga0kA', function=Function(arguments='{\"room_number\":\"101\",\"guest_name\":\"John Smith\",\"request\":\"extra towels\"}', name='extract_user_request_detail'), type='function')])\n"
     ]
    }
   ],
   "source": [
    "new_query = \"You are a customer relations manager at a hotel. A guest named John Smith is staying in room 101 and has requested extra towels. Write a message to the housekeeping staff instructing them to fulfill the request.\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You help user with their request.\",\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": new_query},\n",
    "    ],\n",
    "    model=\"gpt-4-turbo\",\n",
    "    tools=[pydantic_tool],\n",
    "    tool_choice={\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\"name\": \"extract_user_request_detail\"},\n",
    "    },\n",
    ")\n",
    "\n",
    "pydantic_resp = response.choices[0].message\n",
    "\n",
    "print(pydantic_resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'room_number': '101', 'guest_name': 'John Smith', 'request': 'extra towels'}\n"
     ]
    }
   ],
   "source": [
    "parsed_args = message_parser.extract_and_parse_arguments(pydantic_resp)\n",
    "\n",
    "print(parsed_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion: Unlocking Precision and Potential in RAG Systems\n",
    "\n",
    "Throughout this notebook, we've explored various methods to structure and control LLM outputs using JSON parsing techniques. By leveraging direct JSON responses, API function calls, and Pydantic models, we've demonstrated how to obtain precisely formatted data from language models.\n",
    "Key takeaways:\n",
    "\n",
    "* Structured outputs enhance accuracy and integration in RAG systems\n",
    "* JSON parsing techniques provide fine-grained control over LLM responses\n",
    "* Pydantic offers a powerful, type-safe approach to defining and validating data structures\n",
    "\n",
    "The ability to shape LLM outputs into well-defined objects opens up new possibilities:\n",
    "\n",
    "* Seamless integration with databases and APIs\n",
    "* Enhanced data validation and error handling\n",
    "* Simplified post-processing and analysis workflows\n",
    "\n",
    "By mastering these techniques, you're not just parsing JSON â€“ you're unlocking the full potential of your RAG system. With structured, reliable data at your fingertips, you can confidently build more sophisticated applications, integrate advanced tools, and push the boundaries of what's possible with AI-augmented systems.\n",
    "\n",
    "Remember, the key to innovation lies in control and precision. As you continue to develop your RAG pipeline, consider how these parsing techniques can be leveraged to create more powerful, flexible, and reliable LLM-driven solutions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
